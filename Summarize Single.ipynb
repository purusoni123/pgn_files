{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_datafiles import FileTokenizer\n",
    "import run_summarization as run\n",
    "import os\n",
    "import time\n",
    "\n",
    "def summarize(source_text):\n",
    "    stories_dir = os.path.join('stories','Random_Files')\n",
    "    if not os.path.exists(stories_dir):\n",
    "        os.mkdir(stories_dir)\n",
    "    else:\n",
    "        for file in os.listdir(stories_dir):\n",
    "            os.remove(os.path.join(stories_dir, file))\n",
    "    with open(os.path.join(stories_dir, 'random.txt'), 'w+') as file:\n",
    "        file.write(source_text)\n",
    "    #exec(open('run.py').read())\n",
    "    datafiles = FileTokenizer(stories_dir, 'output')\n",
    "    datafiles.make_binfiles()\n",
    "    run.runfiles('output/finished_files/test.bin', '../', 'decode', 'vocab', datafiles)\n",
    "    \n",
    "    # Restarting the kernel\n",
    "    print(\"Restarting\")\n",
    "    #from IPython.core.display import HTML\n",
    "    #HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n",
    "    os._exit(0)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to tokenize stories\\Random_Files to output\\tokenized_stories_dir...\n",
      "Making list of files to tokenize...\n",
      "Tokenizing 1 files in stories\\Random_Files and saving in output\\tokenized_stories_dir...\n",
      "Stanford CoreNLP Tokenizer has finished.\n",
      "Successfully finished tokenizing stories\\Random_Files to output\\tokenized_stories_dir.\n",
      "\n",
      "Writing story 0 of 1; 0.00 percent done\n",
      "output\\tokenized_stories_dir\\random.txt\n",
      "Finished writing file output\\finished_files\\test.bin\n",
      "\n",
      "Deleting files from output\\tokenized_stories_dir\n",
      "Splitting test data into chunks...\n",
      "Saved chunked data in output\\finished_files\\chunked\n",
      "Entering ..................\n",
      "INFO:tensorflow:Starting seq2seq_attention in decode mode...\n",
      "Warning: incorrectly formatted line in vocabulary file: 0800 555 111 356\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 1800 333 000 139\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 2 1/2 124\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 3 1/2 86\n",
      "\n",
      "\n",
      "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
      "Finished constructing vocabulary of 50000 total words. Last word added: perisic\n",
      "INFO:tensorflow:Building graph...\n",
      "INFO:tensorflow:Adding attention_decoder timestep 0 of 1\n",
      "INFO:tensorflow:Time to build graph: 0 seconds\n",
      "Ckpt dir: ../pretrained_model\\train\n",
      "Ckpt state: model_checkpoint_path: \"../pretrained_model\\\\train\\\\model.ckpt-238410\"\n",
      "all_model_checkpoint_paths: \"../pretrained_model\\\\train\\\\model-238410\"\n",
      "all_model_checkpoint_paths: \"../pretrained_model\\\\train\\\\model.ckpt-238410\"\n",
      "\n",
      "INFO:tensorflow:Loading checkpoint ../pretrained_model\\train\\model.ckpt-238410\n",
      "INFO:tensorflow:Restoring parameters from ../pretrained_model\\train\\model.ckpt-238410\n",
      "INFO:tensorflow:\u001b[1m\n",
      "\n",
      " Article: \n",
      "\n",
      "\u001b[0m\u001b[92mAbstractive text summarization is the task of generating a headline or a short summary consisting of a few sentences that captures the salient ideas of an article or a passage .We use the adjective abstractive to denote a summary that is not a mere selection of a few existing passages or sentences extracted from the source , but a compressed paraphrasing of the main contents of the document , potentially using vocabulary unseen in the source document . \u001b[0m\u001b[1m\n",
      "\n",
      " Human Summary: \n",
      "\n",
      "\u001b[0m!!____!!\u001b[1m\n",
      "\n",
      " Generated Summary: \n",
      "\n",
      "\u001b[0m\u001b[94mabstractive text summarization is the task of generating a headline or a short summary consisting of a few existing passages or sentences extracted from the source . a compressed paraphrasing of the main contents of the document , potentially using vocabulary unseen in the source document . \u001b[0m\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary appended to 'summary.txt'\n",
      "INFO:tensorflow:Wrote visualization data to ../pretrained_model\\decode\\2018-08-07_18-24-36\\attn_vis_data_1.json\n",
      "INFO:tensorflow:Summarization Complete. Ending......\n"
     ]
    }
   ],
   "source": [
    "summarize(\"Abstractive text summarization is the task of generating a headline or a short summary consisting of a few sentences that captures the salient ideas of an article or a passage .We use the adjective abstractive to denote a summary that is not a mere selection of a few existing passages or sentences extracted from the source , but a compressed paraphrasing of the main contents of the document , potentially using vocabulary unseen in the source document . \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.display import HTML\n",
    "#HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectname",
   "language": "python",
   "name": "projectname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
